{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python=3.7.6\n",
      "transformers==2.4.1\n",
      "torch==1.2.0\n",
      "tensorflow==2.0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import transformers, torch, tensorflow\n",
    "from platform import python_version\n",
    "print(\"python={}\".format(python_version()))\n",
    "print(\"transformers=={}\\ntorch=={}\\ntensorflow=={}\\n\".\n",
    "      format(transformers.__version__, torch.__version__, tensorflow.__version__ ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use BERT? \n",
    "\n",
    "BERT [open soruce: pytorch](https://github.com/huggingface/transformers)\n",
    "> If you want to use `transformers` module, follow this install [guide](https://huggingface.co/transformers/installation.html?highlight=install).  \n",
    "\n",
    "BERT [document](https://huggingface.co/transformers/index.html#)\n",
    "> Description of how to use `transformers` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 - Setting\n",
    "`import` some libraries, and declare basic variables and fucntions in order to load and use **BERT**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-f:9: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "03/06/2020 18:57:01 - Hellow World!\n"
     ]
    }
   ],
   "source": [
    "import sys, os, argparse, logging, yaml, pdb\n",
    "from transformers import BertConfig, BertPreTrainedModel, BertModel, BertTokenizer\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', default='config.yml', help='read configuration file')\n",
    "sys.argv = ['-f']\n",
    "args = parser.parse_args()\n",
    "with open(args.config, 'r') as f:\n",
    "    opt = yaml.load(f)\n",
    "logger = logging.getLogger(__name__)\n",
    "# setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO if opt['verbose'] else logging.WARNING)\n",
    "logger.info(\"Hellow World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert-base-cased', './cache')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt['config_name'], opt['cache_dir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load configuration object for BERT\n",
    "Prerequsite argument: \n",
    " * `pretrained_model_name_or_path`: the name of BERT model to use.\n",
    "\n",
    "Optional:\n",
    " * `cache_dir`: we can select cache directory to save. \n",
    "   `./cache/b945b69218e98 ... ` file will be saved.\n",
    "> REF: [pack, unpack](https://wikidocs.net/22801) in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2020 18:57:02 - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at ./cache/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e\n",
      "03/06/2020 18:57:02 - Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "03/06/2020 18:57:03 - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/kddlab/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    }
   ],
   "source": [
    "config_bert = BertConfig.from_pretrained(pretrained_model_name_or_path=opt['config_name'], \n",
    "                                         cache_dir=opt['cache_dir'])\n",
    "tokenizer = BertTokenizer.from_pretrained(opt['config_name'], do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2020 18:57:03 - Optional: output all layers' states\n"
     ]
    }
   ],
   "source": [
    "config_bert.output_hidden_states = True\n",
    "logger.info(\"Optional: output all layers' states\".format(config_bert.output_hidden_states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a custom model to make use of BERT.\n",
    "\n",
    "If you wanted, you can make custom model to use BERT. <br>\n",
    "I want to use BERT embedding for my research, so I added a `linear` layer to train for specific task, later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2020 18:57:04 - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at ./cache/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "03/06/2020 18:57:06 - Weights of MyModel not initialized from pretrained model: ['linear.weight', 'linear.bias']\n",
      "03/06/2020 18:57:06 - Weights from pretrained model not used in MyModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "HIDDEN_SIZE_BERT = 768\n",
    "EMBED_SIZE_WORD = 300\n",
    "\n",
    "class MyModel(BertPreTrainedModel):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        \"\"\" Using Bert, define custom Model. \n",
    "        [*]: check important parts. \"\"\"\n",
    "        super(MyModel, self).__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        \n",
    "        # recursively load into the BERT submodule the first time you call pre-trained weights. [*]\n",
    "        self.init_weights()\n",
    "        \n",
    "        # customized layer - these layers' wieghts are not initialized.\n",
    "        self.linear = nn.Linear(kwargs['hidden_size_bert'], kwargs['embed_size_word'])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        \"\"\" forward step of BERT and pass customed layers.\n",
    "        input_ids: prerequesite: \"\"\"\n",
    "        # pdb.set_trace() # debugging\n",
    "        hiddens, pooled, hiddens_all = self.bert(input_ids, \n",
    "                                                 attention_mask=attention_mask,\n",
    "                                                 token_type_ids=token_type_ids)\n",
    "        out = self.linear(hiddens)\n",
    "        return out, hiddens, hiddens_all # [B, T, D]\n",
    "\n",
    "model = MyModel.from_pretrained(\n",
    "    pretrained_model_name_or_path=opt['config_name'], \n",
    "    config=config_bert, \n",
    "    cache_dir=opt['cache_dir'], \n",
    "    hidden_size_bert=HIDDEN_SIZE_BERT,\n",
    "    embed_size_word=EMBED_SIZE_WORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for Dataset to use\n",
    "\n",
    "[REF1 - BERT Word Embeddings Tutorials](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/) <br>\n",
    "[REF2 - Visualization of BERT Embeddings with t-SNE](https://www.kaggle.com/mateiionita/visualizing-bert-embeddings-with-t-sne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a single sentence for being an input of BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
    "       \"fishing on the Mississippi river bank.\"\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "tokens = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
    "input_ids = tokenizer.build_inputs_with_special_tokens(tokens)\n",
    "\n",
    "# optional - discriminate sentence A or B.\n",
    "token_type_ids = tokenizer.create_token_type_ids_from_sequences(tokens)\n",
    "assert len(token_type_ids) == len(input_ids), \"single sentence token tpye ids does not matched.\"\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "input_ids = torch.tensor([input_ids])\n",
    "token_type_ids = torch.tensor([token_type_ids]) + 1 # becomes all 1\n",
    "# input_ids, token_type_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 - Get BERT Embedding by forward step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2020 18:57:06 - eval mode\n",
      "03/06/2020 18:57:06 - torch.Size([1, 27, 300]), torch.Size([1, 27, 768]), 13\n"
     ]
    }
   ],
   "source": [
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n",
    "logger.info(\"eval mode\")\n",
    "\n",
    "# Predict hidden states features for each layer - speed up inference time.\n",
    "with torch.no_grad():\n",
    "    # forward step of a cumstomized model - only output hiddens, not pooled output.\n",
    "    embed, hiddens, hiddens_all = model(input_ids, token_type_ids=token_type_ids)\n",
    "logger.info(\"{}, {}, {}\".format(embed.shape, hiddens.shape, len(hiddens_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, torch.Size([1, 27, 768]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hiddens_all), hiddens_all[0].shape # dim=[#layers, #batches, #tokens, #features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2020 18:57:06 - torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "# set index for getting wanted information\n",
    "batch_i, token_i, layer_i = 0, 5, 5\n",
    "embed_token = hiddens_all[1 + layer_i][batch_i][token_i]\n",
    "logger.info(embed_token.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(embed_token, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape hidden states of BERT-output for analysis.\n",
    "\n",
    "I will **reshape** BERT-output into `[#tokens, #layers, #features]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2020 18:57:07 - torch.Size([12, 1, 27, 768])\n",
      "03/06/2020 18:57:07 - torch.Size([12, 27, 768])\n",
      "03/06/2020 18:57:07 - torch.Size([27, 12, 768])\n"
     ]
    }
   ],
   "source": [
    "logger.info(torch.stack(hiddens_all[1:], dim=0).shape)\n",
    "new_embed = torch.squeeze(torch.stack(hiddens_all[1:], dim=0), dim=1)\n",
    "logger.info(new_embed.shape)\n",
    "new_embed = new_embed.permute(1,0,2)\n",
    "logger.info(new_embed.shape) # complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 - Create word and sentence vertors \n",
    "\n",
    "<div style=\"background-color:gray\"> <summary> <h4>issue</h4> </summary> \n",
    "    <p> which layer or combination of layers provides the best representation? In BERT paper, they compared it by F1-scores. </p>\n",
    "</div>\n",
    "\n",
    "결론: task 마다 다르다. It depends on the situation... what is your applicaiton?\n",
    "> the correct pooling strategy and layers used (last four, all, last layer, etc.) is dependent on the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vectors\n",
    "\n",
    "There are many ways to create word vectors.\n",
    "1. Concatenate the last 4 layers. Each vector will has length $4 \\times 768 = 3072$\n",
    "2. Summation of the last 4 layers. Each vector will has length $768$\n",
    "3. Etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "embed_words = []\n",
    "for embed in new_embed:\n",
    "    # option 1\n",
    "#     vec = torch.cat([x for x in embed[-4:]], dim=0)\n",
    "#     embed_words.append(vec)\n",
    "    # option 2\n",
    "    vec = torch.sum(embed[-4:], dim=0)\n",
    "    embed_words.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2020 18:57:07 - # of tokens: 27, # of dim for each words: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"# of tokens: {}, # of dim for each words: {}\".format(len(embed_words), embed_words[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Vectors\n",
    "\n",
    "There are also many ways to create word vectors.  \n",
    "Take one option.\n",
    "In this blog, I take the average of all tokens' embeddings in the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2020 18:57:07 - torch.Size([25, 768])\n",
      "03/06/2020 18:57:07 - torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "embed_sentence = new_embed[1:-1, -1, :] # except first and last token embedding\n",
    "logger.info(embed_sentence.shape)\n",
    "embed_sentence = torch.mean(embed_sentence, dim=0)\n",
    "logger.info(embed_sentence.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Analysis of a Case Study\n",
    "\n",
    "According to this [article](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#32-understanding-the-output) at section 3.4, the arthor said that \"value of these vectors[sentence and words vectors] are in fact contextually dependent.\" <br>\n",
    "Let's look at the different instances of the word “bank” in our example sentence:\n",
    ">  ''After stealing money from the **bank vault**, the **bank robber** was seen fishing on the Mississippi **river bank**.''\n",
    "\n",
    "Note that each of the three **bank** has different meaning contextually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2020 18:57:07 - After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\n",
      "03/06/2020 18:57:07 - tensor([[  101,  1170, 11569,  1948,  1121,  1103,  3085, 13454,   117,  1103,\n",
      "          3085,   187, 12809,  3169,  1108,  1562,  5339,  1113,  1103,  5529,\n",
      "         14788,  9717,  8508,  2186,  3085,   119,   102]])\n"
     ]
    }
   ],
   "source": [
    "logger.info(text) # recall that text is like this. \n",
    "logger.info(input_ids) # tokenized words' ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2020 18:57:07 - [6, 10, 24]\n"
     ]
    }
   ],
   "source": [
    "# extract indices of bank from a given sentence.\n",
    "indices = [idx for idx, token in enumerate(tokenizer.convert_ids_to_tokens(input_ids.view(-1))) if token=='bank']\n",
    "logger.info(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate cosine similarity between the vectors `embed_words` from step 3 \n",
    "\n",
    "As a human, we can easily notice that \n",
    " * `'bank'` is similar meaning where the `'bank' vault` and the `'bank' robber`.\n",
    " * `'bank'` is different meaning where `river 'bank'` and the `'bank' vault` or the `'bank' robber`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/06/2020 19:12:10 - 27, torch.Size([768])\n",
      "03/06/2020 19:12:10 - ['bank', 'bank', 'bank']\n",
      "03/06/2020 19:12:10 - score1=[[0.8953148]]| score2=[[0.7670008]]| score3=[[0.73296183]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "logger.info(\"{}, {}\".format(len(embed_words), embed_words[0].shape))\n",
    "\n",
    "logger.info(tokenizer.convert_ids_to_tokens([input_ids.view(-1)[6].item(), \n",
    "                                             input_ids.view(-1)[10].item(), \n",
    "                                             input_ids.view(-1)[24].item()]))\n",
    "\n",
    "score1 = cosine_similarity(embed_words[6].view(1, -1), embed_words[10].view(1, -1)) # similar\n",
    "score2 = cosine_similarity(embed_words[6].view(1, -1), embed_words[24].view(1, -1)) # different\n",
    "score3 = cosine_similarity(embed_words[10].view(1, -1), embed_words[24].view(1, -1)) # different\n",
    "logger.info(\"score1={}| score2={}| score3={}\".format(score1, score2, score3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report\n",
    " According to the author of this article \n",
    "> it is worth noting that **word-level similarity comparisons are not appropriate** with BERT embeddings because these embeddings are contextually dependent. This makes direct word-to-word similarity comparisons less valuable.\n",
    "\n",
    "결론: 문맥에 따라 벡터 표현이 다르므로 **word 간의 similarity 비교**는 큰 의미가 **없다**.\n",
    "\n",
    "하지만, BERT는 sentence가 같으면 벡터가 같도록 디자인 하였기 때문에 **sentence 사이의 similarity**는 의미가 있을 수 **있다**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swyoo",
   "language": "python",
   "name": "swyoo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
